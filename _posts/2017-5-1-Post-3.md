---
layout: post
title: Using machine learning to predict diabetes-related complications with minimal data
---

According to the American Diabetes Association, 29 million people in the United States currently suffer from diabetes,
which works out to an astounding 1 in 11 individuals. Even more troubling, 86 million americans are [prediabetic](http://www.mayoclinic.org/diseases-conditions/prediabetes/home/ovc-20270022), and 90% of them don't even know it. While the implications of these statistics for individual health may be obvious, the economic effects of such widespread diabetes are also worth noting: the total cost of treatment for diabetes and prediabetes in the US is estimated at $322 billion dollars annually, and diabetic patients cost more than twice as much to treat as the general population--an multiplier that is only expected to increase in size, given [the rising costs of diabetes drugs](http://www.cbsnews.com/news/insulin-prices-rise-yet-again-causing-diabetics-to-cry-foul/). 

Part of the reason why diabetes is so difficult and costly to treat is its chronic and systemic nature: because it's the result of failure to effectively regulate the amount of sugar in the blood, it can affect any part of the body where blood goes (read: everywhere). Left uncontrolled, high blood sugar can wreak havoc on a number of crucial organs: 

![Chronic diabetes can cause serious complications]({{ site.baseurl}}/images/post_3/diabetes_complications.png)

For my second independent project at Metis--a classification challenge--I desperately wanted to diagnostic work with a medical dataset, but it's actually quite difficult to get access to a health record dataset of any real size without insitutional backing. This is, of course, by design (and a good thing), but it made my quest somewhat difficult. Luckily, a machine learning group at Virginia Commonwealth University has [compiled 100k-point dataset of hospital visit outcomes for diabetic patients](https://www.hindawi.com/journals/bmri/2014/781670/) across a number of hospitals in the US and generously [made it available](https://archive.ics.uci.edu/ml/datasets/Diabetes+130-US+hospitals+for+years+1999-2008) through the UCI machine learning repository. In their analysis, the original group used the data they gathered to make a binary prediction: given a patient's history and the treatment they received in their hospital visit, would they be re-admitted within 30 days? 

While their findings were interesting and meaningful, I was still stuck on the idea of a diagnostic challenge and didn't want to simply replicate the original group's approach. After playing with the dataset for a couple days, I realized I could essentially turn it inside out and use it for a diagnostic dataset: each patient was entered in the records with a primary diagnosis, i.e. the primary condition that caused them to come to the hospital in the first place. It occurred to me that if I could use only the data in the records about the patient's past and throw out all the data generated during the hospital visit, I might be able to uncover some meaningful predictors of specific diabetes complications. In theory, if this approach worked, it would allow health providers to catch (and treat) high-risk patients *before* they turned up at the hospital with extremely serious complications. Better health outcomes *and* lower costs of treatment. 
Unfortunately for me, this project also turned into a test of the limits of machine learning. Once I cleaned the dataset of duplicates, incomplete records and irrelevant records, I was down to about 25k datapoints (from an original 100k). Still, not bad! But once I threw out any data generated after the patient entered the hospital, I wasn't left with very much: which drugs they were on, where they had been admitted from, how many hospital/doctor visits they'd had in the past, and their age, gender and weight. Ultimately, not a lot of potential predictors there. Perhaps not surprisingly, the two models I built for my initial attempt at diagnosis prediction didn't work very well: 

![Diabetic model performance]({{ site.baseurl}}/images/post_3/Slide10.jpg "Not...super accurate. Not really accurate at all.")

But after playing around a little more, I realized there was one attribute that I had thrown out that I might be able to use after all: the HbA1c assay results. This is a blood sugar test that can detect long-term accumulation of sugar in the blood, so it speaks as much about the past as it does about the present. More importantly, I could cheat a little and use it as a datapoint in my analysis! Here's what happens when you add the HbA1c data back in: 

![Diabetic models with HbA1c]({{ site.baseurl}}/images/post_3/Slide13.jpg "A little better!")

Still not great, but quite an improvement over the original model. Ultimately, this analysis would almost certainly be a lot more powerful with more health data from *before* the patients arrived at the hospital, but it ended up performing fairly impressively when you consider the minimal amount of data there was to work with in the stripped-down dataset. 